# distPySpark
PySpark in calculating statistics and matrices, done for a project in distributed systems at UH CS.

My solution for selecting the median is to divide the numbers into n buckets based on their shared prefix. For example I first implemented a function to divide the numbers into 100 buckets according to their integer value when the decimal part is removed: 0,1,2,...,99. I then counted the items in each bucket and sorted the buckets: sorting 100 items is a quick task and therefore I think it was justifiable. Then I selected the bucket in which the index of the median (dataset size divided by two) was located, sorted that bucket and selected the median based on the difference of the index of the median and sum of items in discarded buckets. Offset calculated that way indicates the index of the median in the selected bucket.

Because sorting approximately 1 000 000 000 / 100 items is time consuming, I tried to use recursion to divide the bucket further, but it appeared to be too slow. Therefore I switched to a solution, where the original dataset is divided into 10 000 buckets. Sorting 10 000 items takes approximately 0.0045s with my laptop, so itâ€™s definitely not a bottleneck here. Dividing into 10 000 buckets decreases the item count within a bucket to 100 000 items on average, which sorts in approximately 0.068s on my setup. With this solution I was able to get the solution to run in 10 minutes using 20 cores. I think that my solution utilizes concurrency where it is most efficient: by assigning the values to the buckets (keys for each value), counting the values and filtering the right bucket.

The mode is "calculated" by measuring the data set. The data set in the task was very flat, so it wasn't exactly meaningful to find the exact mode(s). 

The matrix tasks are supposed to calculate for a matrix A (1 000 000 x 1000) following: A x A{^T} x A. The knack is at first calculate the transpose times A, because this results in 1000x1000 matrix, instead of 1 000 000 x 1 000 000 matrix. The concurrency is utilized so that the matrix is divided to partitions and the Spark workers calculate A{^T} x A for some slice of the matrix. The slices are 1000 columns and n rows, but the result is always 1000 x 1000. Then the partial results are summed elementwise. The result matrix R is then used to finish the calculation of A x R, this too by dividing the calculation to the workers to be executed concurrently (the result matrix R is given as such to each partition) and then concatenated to form the final result. 

The function diag calculates the diagonal for A x A{^T}, which is just all the elements raised to square each and the whole row summed, for each row separately. 
